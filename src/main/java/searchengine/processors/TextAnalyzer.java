package searchengine.processors;

import lombok.extern.slf4j.Slf4j;
import org.apache.lucene.morphology.LuceneMorphology;
import org.apache.lucene.morphology.russian.RussianLuceneMorphology;
import org.springframework.stereotype.Component;

import java.io.IOException;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

@Component
@Slf4j
public class TextAnalyzer {
    private final LuceneMorphology luceneMorphology;
    private static final String WORD_TYPE_REGEX = "\\W\\w&&[^–∞-—è–ê-–Ø\\s]";
    private static final String[] particlesNames = new String[]{"–ú–ï–ñ–î", "–ü–†–ï–î–õ", "–°–û–Æ–ó"};

    public static TextAnalyzer getInstance() throws IOException {
        LuceneMorphology morphology = new RussianLuceneMorphology();
        return new TextAnalyzer(morphology);

    }
    public TextAnalyzer(LuceneMorphology luceneMorphology) {
        this.luceneMorphology = luceneMorphology;
    }

    // üîπ 1. –í—ã–¥–µ–ª–µ–Ω–∏–µ –ª–µ–º–º –∏–∑ —Å—Ç—Ä–æ–∫–∏ (–ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å)
    public List<String> extractLemmas(String text) {
        List<String> result = new ArrayList<>();
        String[] words = preprocessText(text);

        for (String word : words) {
            if (word.isBlank()) continue;

            try {
                List<String> morphInfo = luceneMorphology.getMorphInfo(word);
                if (isServiceWord(morphInfo)) continue;

                List<String> normalForms = luceneMorphology.getNormalForms(word);
                if (!normalForms.isEmpty()) {
                    result.add(normalForms.get(0));
                }
            } catch (Exception e) {
                log.debug("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Å–ª–æ–≤–æ '{}': {}", word, e.getMessage());
            }
        }
        return result;
    }

    public HashMap<String, Integer> analyseText(String text) {
        String[] words = preprocessText(text);
        HashMap<String, Integer> lemmas = new HashMap<>();

        for (String word : words) {
            if (word.isBlank()) {
                continue;
            }

            try {
                List<String> wordBaseForms = luceneMorphology.getMorphInfo(word);
                if (isServiceWord(wordBaseForms)) {
                    continue;
                }

                List<String> normalForms = luceneMorphology.getNormalForms(word);
                if (normalForms.isEmpty()) {
                    continue;
                }

                String lemma = normalForms.get(0);
                lemmas.put(lemma, lemmas.getOrDefault(lemma, 0) + 1);
            } catch (Exception e) {
                log.debug("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–æ '{}': {}", word, e.getMessage());
            }
        }

        return lemmas;
    }

    // –°—Ç—Ä–æ–∏—Ç —Å–Ω–∏–ø–ø–µ—Ç ‚Äî –æ—Ç—Ä—ã–≤–æ–∫ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º —Å–æ–≤–ø–∞–≤—à–∏—Ö –ª–µ–º–º
    public String buildSnippet(String htmlContent, List<String> queryLemmas) {
        String text = clearHtml(htmlContent);
        if(text.isBlank()) return "";

        // –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        String[] words = text.split("\\s+");

        // –ü—Ä–∏–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å –∫ –º–Ω–æ–∂–µ—Å—Ç–≤—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        Set<String> targetLemmas = new HashSet<>(queryLemmas);

        // –ò—â–µ–º –ø–µ—Ä–≤—É—é –ø–æ–∑–∏—Ü–∏—é —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        int matchIndex = -1;
        for (int i = 0; i < words.length; i++) {
            String cleaned = words[i].toLowerCase(Locale.ROOT).replaceAll("[^–∞-—è—ë]", "");
            if (cleaned.isBlank()) continue;

            try {
                List<String> normalForms = luceneMorphology.getNormalForms(cleaned);
                if (!normalForms.isEmpty() && targetLemmas.contains(normalForms.get(0))) {
                    matchIndex = i;
                    break;
                }
            } catch (Exception e) {
                log.debug("–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ '{}': {}", cleaned, e.getMessage());
            }


        }

        // –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –≤–µ—Ä–Ω—É—Ç—å –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞
        if (matchIndex == -1) {
            return text.length() > 300 ? text.substring(0, 300) + "..." : text;
        }

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Å–Ω–∏–ø–ø–µ—Ç–∞ (~50 —Å–ª–æ–≤ ‚âà 3 —Å—Ç—Ä–æ–∫–∏)
        int start = Math.max(0, matchIndex - 25);
        int end = Math.min(words.length, matchIndex + 25);

        // –°–æ–±–∏—Ä–∞–µ–º —Å–Ω–∏–ø–ø–µ—Ç
        StringBuilder snippet = new StringBuilder();
        for (int i = start; i < end; i++) {
            String originalWord = words[i];
            String cleaned = originalWord.toLowerCase(Locale.ROOT).replaceAll("[^–∞-—è—ë]", "");

            boolean highlight = false;

            // –ï—Å–ª–∏ —Å–ª–æ–≤–æ –≤ —Å–ø–∏—Å–∫–µ –ª–µ–º–º ‚Äî –≤—ã–¥–µ–ª—è–µ–º –∂–∏—Ä–Ω—ã–º
            try {
                List<String> normalForms = luceneMorphology.getNormalForms(cleaned);
                highlight = !normalForms.isEmpty() && targetLemmas.contains(normalForms.get(0));
            } catch (Exception ignored) {
            }

            if (highlight) {
                snippet.append("<b>").append(originalWord).append("</b>");
            } else {
                snippet.append(originalWord);
            }
            snippet.append(" ");
        }

        return snippet.toString().trim() + "...";

    }

    private String[] preprocessText(String text) {
        return text.toLowerCase(Locale.ROOT)
                .replaceAll("([^–∞-—è—ë\\s])", " ")
                .trim()
                .split("\\s+");
    }

    private boolean isParticle(List<String> wordBaseForms) {
        return wordBaseForms.stream()
                .anyMatch(this::hasParticleProperty);
    }

    private boolean hasParticleProperty(String wordBase) {
        for (String property : particlesNames) {
            if (wordBase.toUpperCase().contains(property)) {
                return true;
            }
        }
        return false;
    }

    // –û—á–∏—â–∞–µ—Ç HTML –æ—Ç —Ç–µ–≥–æ–≤
    public String clearHtml(String htmlContent) {
        if (htmlContent == null) return "";
        return htmlContent.replaceAll("<[^>]+>", "").replaceAll("\\s+", " ").trim();
    }

    // üîπ –ò–∑–≤–ª–µ–∫–∞–µ—Ç <title> —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    public String extractTitle(String htmlContent) {
        if (htmlContent == null) return "";
        Matcher matcher = Pattern.compile("<title>(.*?)</title>", Pattern.CASE_INSENSITIVE).matcher(htmlContent);
        return matcher.find() ? matcher.group(1).trim() : "";
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤
    private boolean isServiceWord(List<String> wordBaseForms) {
        return wordBaseForms.stream()
                .anyMatch(form -> {
                    String[] parts = form.split("\\|");
                    if (parts.length < 2) return false;
                    String partOfSpeech = parts[1].trim().toUpperCase();
                    for (String particle : particlesNames) {
                        if (partOfSpeech.contains(particle)) return true;
                    }
                    return false;
                });
    }
}
